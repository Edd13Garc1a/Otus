Проект Otus: Веб-приложение с мониторингом и репликацией базы данных
Обзор
Этот проект представляет собой комплексную инфраструктуру веб-приложения с корзиной покупок, репликацией базы данных MySQL, мониторингом и логированием. Он демонстрирует полнофункциональное решение с балансировкой нагрузки, высокой доступностью и возможностями мониторинга, подходящее для продакшен-среды. Проект разработан для демонстрации навыков системного администрирования, практик DevOps и веб-разработки.
Приложение представляет собой PHP-приложение корзины покупок, работающее на серверах Apache с балансировкой нагрузки через Nginx. Для обеспечения надежности данных используется настройка репликации MySQL master-slave. Мониторинг реализован с использованием Prometheus, Node Exporter и Grafana, а логирование осуществляется с помощью стека ELK (Elasticsearch, Logstash, Kibana). Регулярные резервные копии базы данных отправляются в репозиторий GitHub для восстановления в случае сбоя.
Цели проекта

Развертывание масштабируемого веб-приложения с балансировкой нагрузки.
Обеспечение надежности данных через репликацию MySQL master-slave.
Реализация мониторинга и логирования для наблюдения за системой.
Автоматизация резервного копирования базы данных и хранение в репозитории GitHub.
Обеспечение механизма восстановления базы данных из резервных копий.

Архитектура
Система состоит из нескольких компонентов, работающих вместе для обеспечения надежности и мониторинга веб-приложения.
<img width="1164" height="632" alt="image" src="https://github.com/user-attachments/assets/f30bb9a0-e452-4efc-a3a3-7d71a7a7d1cc" />


Компоненты

Nginx: Балансировщик нагрузки, распределяет запросы между тремя экземплярами Apache (порты 8080, 8081, 8082).
Apache: Веб-серверы, обслуживающие PHP-приложение корзины покупок.
MySQL Master-Slave: Основной сервер (192.168.33.245) и сервер реплики (192.168.33.246) для обеспечения надежности данных.
Prometheus и Node Exporter: Сбор метрик с сервера и их хранение для мониторинга.
Grafana: Визуализация метрик через дашборды.
ELK Stack: Filebeat собирает логи Nginx, отправляет их в Elasticsearch, а Kibana предоставляет интерфейс для анализа логов.
GitHub: Хранилище для резервных копий базы данных.

Требования

ОС: Ubuntu (или другой Linux-дистрибутив, совместимый с apt).
Права root для выполнения скриптов установки.
Доступ к интернету для загрузки пакетов и зависимостей.
SSH-доступ между серверами (для репликации и резервного копирования).
GitHub репозиторий для хранения резервных копий.

Установка
Все скрипты находятся в корневой директории проекта и должны выполняться с правами root.

Установка веб-приложения (1_install.sh):
sudo bash 1_install.sh


Устанавливает Nginx, Apache, MySQL и PHP.
Настраивает балансировку нагрузки на порты 8080, 8081, 8082.
Создает базу данных Otus_test и таблицу cart для корзины покупок.
Проверяет запуск сервисов и доступность приложения по адресам:
Балансировка: http://192.168.33.245/
Прямой доступ: http://192.168.33.245:8080, :8081, :8082




Настройка репликации MySQL (2_install_mysql.sh):
sudo bash 2_install_mysql.sh


Настраивает мастер (192.168.33.245) и слейв (192.168.33.246) для репликации.
Создает пользователя для репликации (replicator) и базу данных Otus_test.
Проверяет статус репликации.


Установка мониторинга (3_install_monitoring.sh):
sudo bash 3_install_monitoring.sh


Устанавливает Node Exporter (порт 9100), Prometheus (порт 9090) и Grafana (порт 3000).
Настраивает сбор метрик и визуализацию в Grafana.


Установка ELK Stack (4_install_elk.sh):
sudo bash 4_install_elk.sh


Устанавливает Elasticsearch, Kibana (порт 5601) и Filebeat.
Настраивает сбор логов Nginx и их отображение в Kibana.


Резервное копирование (5_backup_slave_and_push.sh):
sudo bash 5_backup_slave_and_push.sh


Останавливает репликацию на слейве, создает резервную копию базы данных.
Архивирует и отправляет копию в GitHub репозиторий.
Возобновляет репликацию и проверяет её статус.


Восстановление базы данных (6_restore_db_master.sh):
sudo bash 6_restore_db_master.sh


Клонирует GitHub репозиторий, извлекает последнюю резервную копию.
Восстанавливает базу данных Otus_test на мастере.



Использование

Веб-приложение:

Доступ через http://192.168.33.245/ (балансировка нагрузки).
Прямой доступ к серверам: http://192.168.33.245:8080, :8081, :8082.
Функционал: добавление/удаление товаров в корзину, отображение IP клиента и порта сервера.


Мониторинг:

Prometheus: http://192.168.33.245:9090 — просмотр метрик.
Grafana: http://192.168.33.245:3000 (логин/пароль: admin/admin) — дашборды для визуализации метрик.


Логирование:

Kibana: http://192.168.33.245:5601 — дашборд для анализа логов Nginx.
Откройте в Kibana: Analytics → Dashboard → [Filebeat Nginx] Access and error logs.


Резервное копирование и восстановление:

Резервные копии автоматически создаются и отправляются в GitHub.
Для восстановления используйте скрипт 6_restore_db_master.sh.



Проверка работоспособности

Веб-приложение: Обновите страницу http://192.168.33.245/ несколько раз, чтобы увидеть, как запросы распределяются между портами 8080, 8081, 8082.
Репликация: Проверьте статус репликации на слейве:mysql -u root -p'Testpass1$' -e "SHOW SLAVE STATUS\G"

Убедитесь, что Slave_IO_Running и Slave_SQL_Running имеют значение Yes.
Мониторинг: Проверьте метрики в Prometheus (http://192.168.33.245:9090) и дашборды в Grafana (http://192.168.33.245:3000).
Логирование: Просмотрите логи Nginx в Kibana (http://192.168.33.245:5601).
Резервное копирование: Проверьте наличие файлов Otus_test_*.sql.tar.gz в GitHub репозитории.


Заключение
Проект демонстрирует комплексный подход к развертыванию веб-приложения с учетом масштабируемости, надежности и мониторинга. Он объединяет современные инструменты и практики DevOps, включая балансировку нагрузки, репликацию базы данных, мониторинг и логирование, а также автоматизацию резервного копирования и восстановления. Проект готов к демонстрации и может быть расширен для реальных производственных сценариев.
